{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  transforms = transforms.Compose([\n",
    "    transforms.\n",
    "    Resize(8),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,)),\n",
    "      ])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=r\"C:\\Users\\DELL\\Desktop\\projects\\GAN Data\", transform=transform),\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=20)\n",
    "\n",
    "img_shape = (1, 8, 8)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(8*8, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128,1)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.leaky_relu( self.fc1(x),0.2)\n",
    "        x = F.leaky_relu(self.fc2(x),0.2)\n",
    "        x = F.leaky_relu(self.fc3(x),0.2)\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 128)\n",
    "        self.fc2 = nn.Linear(128,512)\n",
    "        self.fc3 = nn.Linear(512,1024 )\n",
    "        self.fc4 = nn.Linear(1024,8*8)\n",
    "        self.in1 = nn.BatchNorm1d(128)\n",
    "        self.in2 = nn.BatchNorm1d(512)\n",
    "        self.in3 = nn.BatchNorm1d(1024)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x),0.2)\n",
    "        x = F.leaky_relu(self.in2(self.fc2(x)),0.2)\n",
    "        x = F.leaky_relu(self.in3(self.fc3(x)),0.2)\n",
    "        x = F.tanh(self.fc4(x))\n",
    "        return x.view(x.shape[0],*img_shape)\n",
    "    \n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "loss_func = torch.nn.BCELoss()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002,betas=(0.4,0.999)) # For generator\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002,betas=(0.4,0.999))# For discriminator\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "                  \n",
    "for epoch in range(10):\n",
    "    for batch_idx,(data,targets) in enumerate(dataloader):\n",
    "        #ground truths\n",
    "        val = Tensor(imgs.size(0), 1).fill_(1.0)\n",
    "        fake = Tensor(imgs.size(0), 1).fill_(0.0)\n",
    "        real_imgs = imgs.cuda()\n",
    "        optimizer_G.zero_grad()\n",
    "        gen_input = Tensor(np.random.normal(0, 1, (imgs.shape[0],100)))\n",
    "        gen = generator(gen_input)\n",
    "        #generator loss gives the measure of ability to fool discriminator\n",
    "        g_loss = loss_func(discriminator(gen), val)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = loss_func(discriminator(real_imgs), val)\n",
    "        fake_loss = loss_func(discriminator(gen.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" % (epoch, 20, i, len(dataset),\n",
    "                                                            d_loss.item(), g_loss.item()))\n",
    "        total_batch = epoch * len(dataset) + i\n",
    "        if total_batch % 400 == 0:\n",
    "            save_image(gen.data[:25], 'output/%d.png' % total_batch, nrow=5, normalize=True)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
